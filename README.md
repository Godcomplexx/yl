# Сборщик Кинематографичного Датасета

Этот проект представляет собой набор Python-скриптов для автоматического создания датасета из коротких, кинематографичных видеоклипов с YouTube. Пайплайн выполняет поиск, загрузку, обработку и валидацию клипов, чтобы обеспечить их высокое качество и уникальность.

## Возможности

- **Поиск по ключевым словам**: Находит видео на YouTube, используя список ключевых слов из файла `config.yaml`.
- **Автоматическая загрузка**: Использует `yt-dlp` для скачивания видео.
- **Расширяемый парсер**: Построен на архитектуре "Стратегия", что позволяет легко добавлять новые источники (TikTok, Vimeo и др.), не меняя основной код. Изначально реализована стратегия для YouTube.
- **Фильтрация по длительности**: Перед скачиванием отсеивает слишком длинные видео.
- **Нарезка клипов**: Вырезает случайные 5-секундные фрагменты из загруженных роликов.
- **Продвинутая дедупликация**: Применяет перцептивное хеширование (`videohash`) для предотвращения дубликатов.
- **Детекция водяных знаков**: Алгоритм находит статичные элементы (логотипы, текст, плашки), которые остаются неподвижными относительно кадра, даже если камера движется. Процесс состоит из следующих шагов:
    1. Из видео извлекаются два кадра из разных временных точек (например, на 1-й и 4-й секундах).
    2. С помощью алгоритма ORB на обоих кадрах находятся ключевые точки (углы, контрастные области).
    3. Эти точки сопоставляются, чтобы понять, как изменилось изображение (например, из-за движения камеры).
    4. Один кадр "накладывается" на другой с учетом этого движения (вычисляется гомография).
    5. Вычисляется разница между совмещенными кадрами. В результате движущиеся объекты сцены исчезают, а статичные элементы (водяные знаки) остаются видимыми.
    6. Если площадь таких статичных областей превышает заданный порог, видео помечается как содержащее водяной знак и отбраковывается.
- **Структурированный датасет**: Организует готовые клипы в папки по ключевым словам и генерирует `index.csv` с метаданными.
- **Автоматический отчет**: Создает файл `report.md` с краткой статистикой по собранному датасету.
- **Архивация**: Упаковывает готовый датасет в `.zip` архив для удобной передачи.

---

## Установка и Использование

### 1. Предварительные требования

**Критически важно: у вас должен быть установлен [FFmpeg](https://ffmpeg.org/download.html) и доступен в системной переменной PATH.**

Наши скрипты для обработки видео и `yt-dlp` напрямую зависят от FFmpeg. Без него скрипт не будет работать.

Чтобы проверить, установлен ли FFmpeg, выполните команду:
```bash
ffmpeg -version
```

### 2. Установка

Склонируйте репозиторий и установите необходимые Python-пакеты:

```bash
# Клонируйте репозиторий (если еще не сделали)
git clone <URL репозитория>


# Установите зависимости
pip install -r requirements.txt
```

### 3. Конфигурация

Перед запуском вы можете настроить процесс сбора данных, отредактировав файл `config.yaml`:

- **`keywords`**: Добавляйте или удаляйте ключевые слова для поиска видео разных стилей.
- **`scraper.search_prefix`**: Определяет, сколько видео искать по каждому ключевому слову (например, `ytsearch10` проверит топ-10 результатов).
- **`scraper.download_limit_per_keyword`**: Ограничивает количество скачиваемых видео для каждого ключевого слова.
- **`scraper.max_video_duration`**: Максимальная длительность видео в секундах, которое будет рассматриваться для скачивания (например, `900` для 15 минут).
- **`processing.clip_duration`**: Длительность итоговых клипов в секундах.

### 4. Запуск скрипта

Когда все настроено, запустите пайплайн, выполнив `main.py` из корневой директории проекта:

```bash
python src/main.py
```

Скрипт выполнит все шаги автоматически. Вы можете следить за его прогрессом в консоли и в файле `logs/run.log`.

---

## Структура Проекта

```bash
cinematic-dataset/
├── config.yaml           # Файл конфигурации: ключевые слова, лимиты и пути
├── requirements.txt      # Список Python-зависимостей для установки
├── src/                  # Папка с исходным кодом
│   ├── main.py           # Главный скрипт: запускает и координирует все этапы
│   ├── scraper.py        # Модуль для поиска и скачивания видео с YouTube
│   ├── processing.py     # Модуль обработки: нарезка, хеширование, детекция вотермарок
│   └── utils/
│       └── logger.py     # Утилита для настройки логирования (вывод в консоль и файл)
├── logs/                 # Папка для хранения лог-файлов выполнения
├── dataset/              # Итоговый датасет: клипы, индексный файл и отчет
└── README.md             # Этот файл
```
